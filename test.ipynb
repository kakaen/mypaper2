{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[4, 1, 256, 256]' is invalid for input of size 29584",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m fe\u001b[38;5;241m=\u001b[39mFeatureMatching()\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#reMap[4,1,256,256] indexMap\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m reMap,indexMap\u001b[38;5;241m=\u001b[39m\u001b[43mfe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43mref\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(reMap\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(indexMap\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/.conda/envs/ljetorch/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/ljetorch/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/MySTFProject/SRSTFM/Module/attention.py:89\u001b[0m, in \u001b[0;36mFeatureMatching.forward\u001b[0;34m(self, query, key, flag_8k)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m# 获取最大匹配得分的索引hard_indices\u001b[39;00m\n\u001b[1;32m     88\u001b[0m relavance_maps, hard_indices \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(y, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m#[N, H*W]   \u001b[39;00m\n\u001b[0;32m---> 89\u001b[0m relavance_maps \u001b[38;5;241m=\u001b[39m \u001b[43mrelavance_maps\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape_query\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape_query\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape_query\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m      \n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m relavance_maps,  hard_indices\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[4, 1, 256, 256]' is invalid for input of size 29584"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from common import *\n",
    "from Module.attention import *\n",
    "# bk=BasicBlock(default_conv,6,64,3,1,True,False,act=nn.LeakyReLU(0.2,False))\n",
    "shape=(4,6,512,512)\n",
    "lr=torch.randn(shape).to(dtype=torch.float32)\n",
    "ref=torch.randn(shape).to(dtype=torch.float32)\n",
    "fe=FeatureMatching()\n",
    "#reMap[4,1,256,256] indexMap\n",
    "reMap,indexMap=fe(lr,ref,True)\n",
    "print(reMap.shape)\n",
    "print(indexMap.shape)\n",
    "print(reMap)\n",
    "print(indexMap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 144, 7396])\n",
      "7396\n"
     ]
    }
   ],
   "source": [
    "from tools.tool import extract_image_patches\n",
    "shape=(4,16,256,256)\n",
    "L1=torch.randn(shape)\n",
    "L1_patch=extract_image_patches(L1,(3,3),(3,3),(1,1))\n",
    "print(L1_patch.size())\n",
    "print(86*86)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/u2023170762/.conda/envs/ljetorch/lib/python3.8/site-packages/rasterio/__init__.py:304: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.\n",
      "  dataset = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)\n",
      "/home/u2023170762/.conda/envs/ljetorch/lib/python3.8/site-packages/rasterio/__init__.py:304: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.\n",
      "  dataset = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)\n",
      "/home/u2023170762/.conda/envs/ljetorch/lib/python3.8/site-packages/rasterio/__init__.py:304: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.\n",
      "  dataset = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)\n",
      "/home/u2023170762/.conda/envs/ljetorch/lib/python3.8/site-packages/rasterio/__init__.py:304: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.\n",
      "  dataset = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)\n",
      "/home/u2023170762/.conda/envs/ljetorch/lib/python3.8/site-packages/rasterio/__init__.py:304: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.\n",
      "  dataset = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)\n",
      "/home/u2023170762/.conda/envs/ljetorch/lib/python3.8/site-packages/rasterio/__init__.py:304: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.\n",
      "  dataset = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 6, 256, 256])\n",
      "torch.Size([4, 6, 256, 256])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[4, 1, 256, 256]' is invalid for input of size 29584",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(data[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msize())\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(data[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m---> 21\u001b[0m SMap,indexMap\u001b[38;5;241m=\u001b[39m\u001b[43mfe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(SMap)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(indexMap)\n",
      "File \u001b[0;32m~/.conda/envs/ljetorch/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/ljetorch/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/MySTFProject/SRSTFM/Module/attention.py:89\u001b[0m, in \u001b[0;36mFeatureMatching.forward\u001b[0;34m(self, query, key, flag_8k)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m# 获取最大匹配得分的索引hard_indices\u001b[39;00m\n\u001b[1;32m     88\u001b[0m relavance_maps, hard_indices \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(y, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m#[N, H*W]   \u001b[39;00m\n\u001b[0;32m---> 89\u001b[0m relavance_maps \u001b[38;5;241m=\u001b[39m \u001b[43mrelavance_maps\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape_query\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape_query\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape_query\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m      \n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m relavance_maps,  hard_indices\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[4, 1, 256, 256]' is invalid for input of size 29584"
     ]
    }
   ],
   "source": [
    "from data import *\n",
    "from torch.utils.data import DataLoader\n",
    "import rasterio\n",
    "from Module.alignment import *\n",
    "from Module.attention import *\n",
    "paths=get_pair_path(Path(\"/home/u2023170762/MySTFProject/SRSTFM/images\"))\n",
    "print(paths)\n",
    "images=load_image_pair(Path(\"/home/u2023170762/MySTFProject/SRSTFM/images\"))\n",
    "train_dir=Path(\"/home/u2023170762/MySTFProject/SRSTFM/images\")\n",
    "image_size=(2400,2400)\n",
    "patch_size=256\n",
    "patch_stride=200 #原本是200\n",
    "train_set = PatchSet(train_dir,image_size,patch_size, patch_stride)\n",
    "train_loader = DataLoader(train_set, batch_size=4, shuffle=True,drop_last=True,num_workers=6)\n",
    "\n",
    "#定义计算Map下标的模块\n",
    "fe=FeatureMatching()\n",
    "for idx, data in enumerate(train_loader):\n",
    "    print(data[0].size())\n",
    "    print(data[1].size())\n",
    "    SMap,indexMap=fe(data[1],data[0],True)\n",
    "    print(SMap)\n",
    "    print(indexMap)\n",
    "    # print(inputs[1].size())\n",
    "    # SMap,indexMap=fe(inputs[0],inputs[1],True)\n",
    "    # print(SMap.size())\n",
    "    # print(indexMap.size())\n",
    "# #inputs都是一个二维数组[L0,M1] \n",
    "# for inputs in train_loader:\n",
    "#     #数据移动到设备上\n",
    "#     # inputs = [im.to(torch.device('cuda' if torch.cuda.is_available() else 'cpu')) for im in inputs]\n",
    "#     print(inputs[0].size())\n",
    "#     print(inputs[1].size())\n",
    "#     SMap,indexMap=fe(inputs[0],inputs[1],True)\n",
    "#     print(SMap.size())\n",
    "#     print(indexMap.size())\n",
    "\"\"\" F=torch.from_numpy(images[0]).float()\n",
    "M=torch.from_numpy(images[1]).float()\n",
    "F=F.unsqueeze(0)\n",
    "M=M.unsqueeze(0)\n",
    "print(F.shape)\n",
    "print(M.shape)\n",
    "fe=FeatureMatching()\n",
    "#reMap[4,1,256,256] indexMap\n",
    "SMap,indexMap=fe(M,F,True)\n",
    "print(SMap.shape)\n",
    "print(indexMap.shape) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ljetorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
